{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f148895",
   "metadata": {},
   "source": [
    "# Install necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e028553f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e66e425",
   "metadata": {},
   "source": [
    "# Part 1: Introduction to Classification & Evaluation\n",
    "\n",
    "**Objective:** Load the synthetic health data, train a Logistic Regression model, and evaluate its performance.\n",
    "\n",
    "## 1. Setup\n",
    "\n",
    "Import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3c3d40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09bcb2a",
   "metadata": {},
   "source": [
    "## 2. Data Loading\n",
    "\n",
    "Implement the `load_data` function to read the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c52691a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    Load the synthetic health data from a CSV file.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the CSV file\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame containing the data\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # Load the CSV file using pandas\n",
    "    return pd.read_csv(file_path)  # Replace with actual implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98ac7a3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>age</th>\n",
       "      <th>systolic_bp</th>\n",
       "      <th>diastolic_bp</th>\n",
       "      <th>glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoker_status</th>\n",
       "      <th>heart_rate</th>\n",
       "      <th>disease_outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-29 00:00:00.000000</td>\n",
       "      <td>57</td>\n",
       "      <td>113.063416</td>\n",
       "      <td>84.069561</td>\n",
       "      <td>117.475210</td>\n",
       "      <td>25.085796</td>\n",
       "      <td>no</td>\n",
       "      <td>62.719587</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-31 07:33:55.507789</td>\n",
       "      <td>57</td>\n",
       "      <td>121.598849</td>\n",
       "      <td>89.672279</td>\n",
       "      <td>85.120875</td>\n",
       "      <td>24.120608</td>\n",
       "      <td>no</td>\n",
       "      <td>76.314434</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-02-02 00:15:11.379377</td>\n",
       "      <td>57</td>\n",
       "      <td>126.623222</td>\n",
       "      <td>87.619685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.819332</td>\n",
       "      <td>no</td>\n",
       "      <td>62.427785</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-02-04 09:37:12.589164</td>\n",
       "      <td>57</td>\n",
       "      <td>136.999366</td>\n",
       "      <td>89.199774</td>\n",
       "      <td>118.755648</td>\n",
       "      <td>25.039598</td>\n",
       "      <td>no</td>\n",
       "      <td>61.612981</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2023-02-04 20:56:52.838198</td>\n",
       "      <td>57</td>\n",
       "      <td>127.546919</td>\n",
       "      <td>92.644673</td>\n",
       "      <td>98.882007</td>\n",
       "      <td>24.895024</td>\n",
       "      <td>no</td>\n",
       "      <td>77.649615</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id                   timestamp  age  systolic_bp  diastolic_bp  \\\n",
       "0           1  2023-01-29 00:00:00.000000   57   113.063416     84.069561   \n",
       "1           1  2023-01-31 07:33:55.507789   57   121.598849     89.672279   \n",
       "2           1  2023-02-02 00:15:11.379377   57   126.623222     87.619685   \n",
       "3           1  2023-02-04 09:37:12.589164   57   136.999366     89.199774   \n",
       "4           1  2023-02-04 20:56:52.838198   57   127.546919     92.644673   \n",
       "\n",
       "   glucose_level        bmi smoker_status  heart_rate  disease_outcome  \n",
       "0     117.475210  25.085796            no   62.719587                0  \n",
       "1      85.120875  24.120608            no   76.314434                0  \n",
       "2            NaN  24.819332            no   62.427785                0  \n",
       "3     118.755648  25.039598            no   61.612981                0  \n",
       "4      98.882007  24.895024            no   77.649615                0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_data('data/synthetic_health_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bedcb6",
   "metadata": {},
   "source": [
    "## 3. Data Preparation\n",
    "\n",
    "Implement `prepare_data_part1` to select features, split data, and handle missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "668201e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_part1(df, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Prepare data for modeling: select features, split into train/test sets, handle missing values.\n",
    "    \n",
    "    Args:\n",
    "        df: Input DataFrame\n",
    "        test_size: Proportion of data for testing\n",
    "        random_state: Random seed for reproducibility\n",
    "        \n",
    "    Returns:\n",
    "        X_train, X_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # 1. Select relevant features (age, systolic_bp, diastolic_bp, glucose_level, bmi)\n",
    "    # 2. Select target variable (disease_outcome)\n",
    "    # 3. Split data into training and testing sets\n",
    "    # 4. Handle missing values using SimpleImputer\n",
    "    \n",
    "    X = df[['age', 'systolic_bp', 'diastolic_bp', 'glucose_level', 'bmi']]\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    imputer.fit(X)\n",
    "    X_imputed = imputer.transform(X)\n",
    "\n",
    "    y = df['disease_outcome']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "52866224",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = prepare_data_part1(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8199b0",
   "metadata": {},
   "source": [
    "## 4. Model Training\n",
    "\n",
    "Implement `train_logistic_regression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "791ed501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Train a logistic regression model.\n",
    "    \n",
    "    Args:\n",
    "        X_train: Training features\n",
    "        y_train: Training target\n",
    "        \n",
    "    Returns:\n",
    "        Trained logistic regression model\n",
    "    \"\"\"\n",
    "    # Initialize and train a LogisticRegression model\n",
    "\n",
    "    reg = LogisticRegression().fit(X_train, y_train)\n",
    "\n",
    "    return reg # Replace with actual implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07c631e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_logistic_regression(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499e0582",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation\n",
    "\n",
    "Implement `calculate_evaluation_metrics` to assess the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1d4e31ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_evaluation_metrics(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Calculate classification evaluation metrics.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        X_test: Test features\n",
    "        y_test: Test target\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing accuracy, precision, recall, f1, auc, and confusion_matrix\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # 1. Generate predictions\n",
    "    # 2. Calculate metrics: accuracy, precision, recall, f1, auc\n",
    "    # 3. Create confusion matrix\n",
    "    # 4. Return metrics in a dictionary\n",
    "    metrics = dict()\n",
    "    preds = model.predict(X_test)\n",
    "\n",
    "    metrics['accuracy'] = accuracy_score(y_test, preds)\n",
    "    metrics['precision'] = precision_score(y_test, preds, zero_division=0)\n",
    "    metrics['recall'] = recall_score(y_test, preds, zero_division=0)\n",
    "    metrics['f1'] = f1_score(y_test, preds, zero_division=0)\n",
    "    metrics['auc'] = roc_auc_score(y_test, preds)\n",
    "    metrics['confusion_matrix'] = confusion_matrix(y_test, preds)\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "38b3804f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.917462482946794,\n",
       " 'precision': np.float64(0.6617647058823529),\n",
       " 'recall': np.float64(0.3146853146853147),\n",
       " 'f1': np.float64(0.4265402843601896),\n",
       " 'auc': np.float64(0.6486502915074344),\n",
       " 'confusion_matrix': array([[1300,   23],\n",
       "        [  98,   45]])}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = calculate_evaluation_metrics(model, X_test, y_test)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9871ed",
   "metadata": {},
   "source": [
    "## 6. Save Results\n",
    "\n",
    "Save the calculated metrics to a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "84453180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results directory and save metrics\n",
    "# YOUR CODE HERE\n",
    "# 1. Create 'results' directory if it doesn't exist\n",
    "# 2. Format metrics as strings\n",
    "# 3. Write metrics to 'results/results_part1.txt'\n",
    "\n",
    "os.makedirs('results', exist_ok=True)\n",
    "\n",
    "results_dir = os.path.join('results', 'results_part1.txt')\n",
    "\n",
    "with open(results_dir, 'w') as f:\n",
    "    for key, val in metrics.items():\n",
    "        f.write(f\"{key}: {val} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9463ee94",
   "metadata": {},
   "source": [
    "## 7. Main Execution\n",
    "\n",
    "Run the complete workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0fa4be8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9168\n",
      "precision: 0.6615\n",
      "recall: 0.3007\n",
      "f1: 0.4135\n",
      "auc: 0.6420\n",
      "\n",
      "Results Interpretation:\n",
      "best_metric: accuracy\n",
      "worst_metric: recall\n",
      "imbalance_impact_score: 0.6161\n"
     ]
    }
   ],
   "source": [
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Load data\n",
    "    data_file = 'data/synthetic_health_data.csv'\n",
    "    df = load_data(data_file)\n",
    "    \n",
    "    # 2. Prepare data\n",
    "    X_train, X_test, y_train, y_test = prepare_data_part1(df)\n",
    "    \n",
    "    # 3. Train model\n",
    "    model = train_logistic_regression(X_train, y_train)\n",
    "    \n",
    "    # 4. Evaluate model\n",
    "    metrics = calculate_evaluation_metrics(model, X_test, y_test)\n",
    "    \n",
    "    # 5. Print metrics\n",
    "    for metric, value in metrics.items():\n",
    "        if metric != 'confusion_matrix':\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    # 6. Save results\n",
    "    # (Your code for saving results)\n",
    "    \n",
    "    # 7. Interpret results\n",
    "    interpretation = interpret_results(metrics)\n",
    "    print(\"\\nResults Interpretation:\")\n",
    "    for key, value in interpretation.items():\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b603c321",
   "metadata": {},
   "source": [
    "## 8. Interpret Results\n",
    "\n",
    "Implement a function to analyze the model performance on imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "81883a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_results(metrics):\n",
    "    \"\"\"\n",
    "    Analyze model performance on imbalanced data.\n",
    "    \n",
    "    Args:\n",
    "        metrics: Dictionary containing evaluation metrics\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with keys:\n",
    "        - 'best_metric': Name of the metric that performed best\n",
    "        - 'worst_metric': Name of the metric that performed worst\n",
    "        - 'imbalance_impact_score': A score from 0-1 indicating how much\n",
    "          the class imbalance affected results (0=no impact, 1=severe impact)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    # 1. Determine which metric performed best and worst\n",
    "    # 2. Calculate an imbalance impact score based on the difference\n",
    "    #    between accuracy and more imbalance-sensitive metrics like F1 or recall\n",
    "    # 3. Return the results as a dictionary\n",
    "    metrics = {k: v for k, v in metrics.items() if isinstance(v, (int, float))}\n",
    "    best_metric = max(metrics, key=metrics.get)\n",
    "    worst_metric = min(metrics, key=metrics.get)\n",
    "    imbalance_impact_score = metrics['accuracy'] - min(metrics['f1'], metrics['recall'])    \n",
    "    return {\n",
    "        'best_metric': best_metric,\n",
    "        'worst_metric': worst_metric,\n",
    "        'imbalance_impact_score': np.round(imbalance_impact_score, 4)\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "sarahli",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
